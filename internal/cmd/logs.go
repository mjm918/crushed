package cmd

import (
	"context"
	"encoding/json"
	"fmt"
	"io"
	"os"
	"path/filepath"
	"regexp"
	"slices"
	"sort"
	"sync"
	"time"

	"charm.land/log/v2"
	"github.com/charmbracelet/colorprofile"
	"github.com/charmbracelet/crush/internal/config"
	logconf "github.com/charmbracelet/crush/internal/log"
	"github.com/charmbracelet/x/term"
	"github.com/nxadm/tail"
	"github.com/spf13/cobra"
)

const defaultTailLines = 1000

var logsCmd = &cobra.Command{
	Use:   "logs",
	Short: "View crush logs",
	Long:  `View the logs generated by Crush. This command allows you to see the log output for debugging and monitoring.`,
	RunE: func(cmd *cobra.Command, args []string) error {
		cwd, err := cmd.Flags().GetString("cwd")
		if err != nil {
			return fmt.Errorf("failed to get current working directory: %v", err)
		}

		dataDir, err := cmd.Flags().GetString("data-dir")
		if err != nil {
			return fmt.Errorf("failed to get data directory: %v", err)
		}

		follow, err := cmd.Flags().GetBool("follow")
		if err != nil {
			return fmt.Errorf("failed to get follow flag: %v", err)
		}

		tailLines, err := cmd.Flags().GetInt("tail")
		if err != nil {
			return fmt.Errorf("failed to get tail flag: %v", err)
		}

		log.SetLevel(log.DebugLevel)
		log.SetOutput(os.Stdout)
		if !term.IsTerminal(os.Stdout.Fd()) {
			log.SetColorProfile(colorprofile.NoTTY)
		}

		cfg, err := config.Load(cwd, dataDir, false)
		if err != nil {
			return fmt.Errorf("failed to load configuration: %v", err)
		}

		logsDir := filepath.Join(cfg.Options.DataDirectory, "logs")
		var logFiles []string

		// Find all crush log files (including process-specific ones)
		files, err := os.ReadDir(logsDir)
		if err != nil {
			if os.IsNotExist(err) {
				log.Warn("Looks like you are not in a crush project. No logs found.")
				return nil
			}
			return fmt.Errorf("failed to read logs directory: %v", err)
		}

		// Match crush.log and crush-<pid>.log files
		logFilePattern := regexp.MustCompile(`^crush(?:-\d+)?\.log$`)
		for _, file := range files {
			info, err := file.Info()
			if err != nil {
				continue
			}

			// Skip files older than MaxAgeDays
			if time.Since(info.ModTime()) > logconf.MaxAgeDays*24*time.Hour {
				continue
			}

			if !file.IsDir() && logFilePattern.MatchString(file.Name()) {
				logFiles = append(logFiles, filepath.Join(logsDir, file.Name()))
			}
		}

		if follow {
			return followLogs(cmd.Context(), logFiles, tailLines)
		}

		return showLogs(logFiles, tailLines)
	},
}

func init() {
	logsCmd.Flags().BoolP("follow", "f", false, "Follow log output")
	logsCmd.Flags().IntP("tail", "t", defaultTailLines, "Show only the last N lines default: 1000 for performance")
}

type logHeap []string

func (h logHeap) Len() int { return len(h) }
func (h logHeap) Less(i, j int) bool {
	var dataI, dataJ map[string]any
	json.Unmarshal([]byte(h[i]), &dataI)
	json.Unmarshal([]byte(h[j]), &dataJ)

	timeI, _ := time.Parse(time.RFC3339, fmt.Sprintf("%v", dataI["time"]))
	timeJ, _ := time.Parse(time.RFC3339, fmt.Sprintf("%v", dataJ["time"]))
	return timeI.Before(timeJ)
}
func (h logHeap) Swap(i, j int) { h[i], h[j] = h[j], h[i] }
func (h *logHeap) Push(x any)   { *h = append(*h, x.(string)) }
func (h *logHeap) Pop() any {
	old := *h
	n := len(old)
	x := old[n-1]
	*h = old[0 : n-1]
	return x
}

func printInitialLogs(logFiles []string, tailLines int) (int, error) {
	// Collect initial lines from all files (only up to tailLines with priority queue)
	h := &logHeap{}

	for _, file := range logFiles {
		t, err := tail.TailFile(file, tail.Config{
			Follow:      false,
			ReOpen:      false,
			Logger:      tail.DiscardingLogger,
			MaxLineSize: 0,
		})
		if err != nil {
			continue
		}

		for line := range t.Lines {
			if line.Err != nil {
				continue
			}
			// Push to heap
			*h = append(*h, line.Text)
			if h.Len() > tailLines {
				// Pop the oldest line
				h.Pop()
			}
		}
		t.Stop()
	}

	if h.Len() == 0 {
		return 0, nil
	}

	// Print initial lines
	sort.Slice(*h, func(i, j int) bool {
		var dataI, dataJ map[string]any
		json.Unmarshal([]byte((*h)[i]), &dataI)
		json.Unmarshal([]byte((*h)[j]), &dataJ)

		timeI, _ := time.Parse(time.RFC3339, fmt.Sprintf("%v", dataI["time"]))
		timeJ, _ := time.Parse(time.RFC3339, fmt.Sprintf("%v", dataJ["time"]))
		return timeI.Before(timeJ)
	})

	for _, line := range *h {
		printLogLine(line)
	}

	return h.Len(), nil
}

func followLogs(ctx context.Context, logFiles []string, tailLines int) error {
	printedLines, err := printInitialLogs(logFiles, tailLines)
	if err != nil {
		return err
	}
	if printedLines == 0 {
		fmt.Fprintln(os.Stderr, "No logs found")
	} else {
		fmt.Fprintf(os.Stderr, "\nShowing last %d lines from %d log file(s). Now following...\n", printedLines, len(logFiles))
	}

	// Now follow all log files
	tailers := make([]*tail.Tail, 0, len(logFiles))
	for _, file := range logFiles {
		t, err := tail.TailFile(file, tail.Config{
			Follow:   true,
			ReOpen:   true,
			Logger:   tail.DiscardingLogger,
			Location: &tail.SeekInfo{Offset: 0, Whence: io.SeekEnd},
		})
		if err != nil {
			continue
		}
		tailers = append(tailers, t)
	}

	if len(tailers) == 0 {
		return nil
	}

	// Combine all tailers into a single channel
	lineChan := make(chan *tail.Line, len(tailers)*10)
	wg := sync.WaitGroup{}
	for _, t := range tailers {
		wg.Add(1)
		go func(tailInstance *tail.Tail) {
			defer wg.Done()
			for line := range tailInstance.Lines {
				if line != nil && line.Err == nil {
					lineChan <- line
				}
			}
		}(t)
	}

	defer func() {
		for _, t := range tailers {
			t.Stop()
		}
		wg.Wait()
		close(lineChan)
	}()

	for {
		select {
		case line, ok := <-lineChan:
			if !ok {
				return nil
			}
			if line.Err != nil {
				continue
			}
			printLogLine(line.Text)
		case <-ctx.Done():
			return nil
		}
	}
}

func showLogs(logFiles []string, tailLines int) error {
	printedLines, err := printInitialLogs(logFiles, tailLines)
	if err != nil {
		return err
	}

	if printedLines == 0 {
		fmt.Fprintln(os.Stderr, "No logs found")
		return nil
	}

	if printedLines == tailLines {
		fmt.Fprintf(os.Stderr, "\nShowing last %d lines from %d log file(s).\n", tailLines, len(logFiles))
	}

	return nil
}

func printLogLine(lineText string) {
	var data map[string]any
	if err := json.Unmarshal([]byte(lineText), &data); err != nil {
		return
	}
	msg := data["msg"]
	level := data["level"]
	otherData := []any{}
	keys := []string{}
	for k := range data {
		keys = append(keys, k)
	}
	slices.Sort(keys)
	for _, k := range keys {
		switch k {
		case "msg", "level", "time":
			continue
		case "source":
			source, ok := data[k].(map[string]any)
			if !ok {
				continue
			}
			sourceFile := fmt.Sprintf("%s:%d", source["file"], int(source["line"].(float64)))
			otherData = append(otherData, "source", sourceFile)

		default:
			otherData = append(otherData, k, data[k])
		}
	}
	log.SetTimeFunction(func(_ time.Time) time.Time {
		// parse the timestamp from the log line if available
		t, err := time.Parse(time.RFC3339, data["time"].(string))
		if err != nil {
			return time.Now() // fallback to current time if parsing fails
		}
		return t
	})
	switch level {
	case "INFO":
		log.Info(msg, otherData...)
	case "DEBUG":
		log.Debug(msg, otherData...)
	case "ERROR":
		log.Error(msg, otherData...)
	case "WARN":
		log.Warn(msg, otherData...)
	default:
		log.Info(msg, otherData...)
	}
}
